So I just kind of wanted to do the maxmatch part even though I basically just did 01b. 
I ran it using the dictionary based on the input sentences, and also using a general japanese list of words I found online. The ouputs were slightly different. 
The dictionary based on the input sentences lead to a more accurate tokenization since it was limited to only relevant words. 
The version computed with the more complete dictionary is technically less accurate for
these sentences, since it includes some rarer short words that aren't actually used as such in these sentences. 
